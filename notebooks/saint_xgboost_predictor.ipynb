{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAINT Transformer + H2O AutoML Multiplier Prediction\n",
        "\n",
        "This notebook implements a hybrid approach using:\n",
        "1. **SAINT Transformer**: Self-Attention and Intersample Attention Transformer for sequence embeddings\n",
        "2. **Contrastive Learning**: Triplet loss training to learn meaningful sequence representations\n",
        "3. **H2O AutoML**: Automated machine learning on embeddings for final predictions\n",
        "4. **Range Estimation**: Uses training error distribution for prediction intervals\n",
        "\n",
        "**Architecture:**\n",
        "- Sequence length: 30\n",
        "- Transformer generates embeddings for each sequence\n",
        "- H2O AutoML automatically selects best model to predict multiplier from embeddings\n",
        "- Range prediction based on error statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Using device: cpu\n",
            "ðŸ“ CSV File: data/aviator_payouts_global.csv\n",
            "ðŸ“Š Sequence Length: 30\n",
            "ðŸ”¢ Embedding Dimension: 128\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import joblib\n",
        "import warnings\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Tuple, List, Dict, Optional\n",
        "import random\n",
        "from collections import defaultdict\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "\n",
        "# Configuration\n",
        "DATA_FOLDER = 'data'\n",
        "CSV_FILE = os.path.join(DATA_FOLDER, 'aviator_payouts_global.csv')\n",
        "SEQ_LENGTH = 30  # Sequence length\n",
        "EMBEDDING_DIM = 128  # Embedding dimension\n",
        "MODEL_DIR = 'saint_models'\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "PREDICTION_LOG_FILE = 'saint_h2o_predictions_log.csv'\n",
        "\n",
        "print(f\"ðŸ“ CSV File: {CSV_FILE}\")\n",
        "print(f\"ðŸ“Š Sequence Length: {SEQ_LENGTH}\")\n",
        "print(f\"ðŸ”¢ Embedding Dimension: {EMBEDDING_DIM}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Sequence Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded 8456 records\n",
            "ðŸ“… Date range: 2025-12-10 19:32:35 to 2025-12-13 15:56:36\n",
            "ðŸ“Š Multiplier statistics:\n",
            "count    8456.000000\n",
            "mean       10.861961\n",
            "std       115.966587\n",
            "min         1.000000\n",
            "25%         1.290000\n",
            "50%         1.930000\n",
            "75%         3.800000\n",
            "max      6114.720000\n",
            "Name: multiplier, dtype: float64\n",
            "\n",
            "âœ… Prepared 8426 sequences of length 30\n",
            "   Sequences shape: (8426, 30)\n",
            "   Targets shape: (8426,)\n",
            "âœ… Sequences normalized for training\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data\n",
        "def load_csv_data(csv_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load and preprocess CSV data.\"\"\"\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
        "    \n",
        "    df = pd.read_csv(csv_path)\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "    \n",
        "    # Validate multipliers\n",
        "    df['multiplier'] = pd.to_numeric(df['multiplier'], errors='coerce')\n",
        "    df = df[df['multiplier'] >= 1.0]\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Load data\n",
        "df = load_csv_data(CSV_FILE)\n",
        "print(f\"âœ… Loaded {len(df)} records\")\n",
        "print(f\"ðŸ“… Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
        "print(f\"ðŸ“Š Multiplier statistics:\")\n",
        "print(df['multiplier'].describe())\n",
        "\n",
        "# Prepare sequences and targets\n",
        "def prepare_sequences(df: pd.DataFrame, seq_length: int = 30) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Prepare sequences of length seq_length and corresponding targets (next value).\n",
        "    \n",
        "    Returns:\n",
        "        sequences: (n_samples, seq_length) array\n",
        "        targets: (n_samples,) array\n",
        "    \"\"\"\n",
        "    multipliers = df['multiplier'].values\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    \n",
        "    for i in range(seq_length, len(multipliers)):\n",
        "        seq = multipliers[i - seq_length:i]\n",
        "        target = multipliers[i]\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "    \n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "sequences, targets = prepare_sequences(df, SEQ_LENGTH)\n",
        "print(f\"\\nâœ… Prepared {len(sequences)} sequences of length {SEQ_LENGTH}\")\n",
        "print(f\"   Sequences shape: {sequences.shape}\")\n",
        "print(f\"   Targets shape: {targets.shape}\")\n",
        "\n",
        "# Normalize sequences (helps with training stability)\n",
        "sequence_scaler = RobustScaler()\n",
        "# Reshape for scaling: (n_samples * seq_length, 1)\n",
        "sequences_flat = sequences.reshape(-1, 1)\n",
        "sequences_scaled_flat = sequence_scaler.fit_transform(sequences_flat)\n",
        "sequences_scaled = sequences_scaled_flat.reshape(sequences.shape)\n",
        "\n",
        "print(f\"âœ… Sequences normalized for training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SAINT Transformer Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… SAINT Transformer model created\n",
            "   Input shape: torch.Size([4, 30])\n",
            "   Output embedding shape: torch.Size([4, 128])\n",
            "   Model parameters: 830,336\n"
          ]
        }
      ],
      "source": [
        "class SAINTTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    SAINT (Self-Attention and Intersample Attention Transformer) model\n",
        "    for time series sequence embedding.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int = 1,  # Single value per timestep (multiplier)\n",
        "        d_model: int = 128,\n",
        "        nhead: int = 8,\n",
        "        num_layers: int = 4,\n",
        "        dim_feedforward: int = 512,\n",
        "        dropout: float = 0.1,\n",
        "        seq_length: int = 30\n",
        "    ):\n",
        "        super(SAINTTransformer, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        # Input projection: multiplier -> d_model\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        \n",
        "        # Positional encoding (learnable)\n",
        "        self.pos_encoder = nn.Parameter(torch.randn(1, seq_length, d_model))\n",
        "        \n",
        "        # Transformer encoder layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation='gelu'\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        \n",
        "        # Pooling to get sequence embedding (mean + max pooling)\n",
        "        self.pool_proj = nn.Linear(d_model * 2, d_model)\n",
        "        \n",
        "        # Layer normalization\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch_size, seq_length, input_dim) or (batch_size, seq_length)\n",
        "        \n",
        "        Returns:\n",
        "            embeddings: (batch_size, d_model)\n",
        "        \"\"\"\n",
        "        # Handle 2D input (batch_size, seq_length)\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.unsqueeze(-1)  # (batch_size, seq_length, 1)\n",
        "        \n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        \n",
        "        # Project input to d_model\n",
        "        x = self.input_projection(x)  # (batch_size, seq_length, d_model)\n",
        "        \n",
        "        # Add positional encoding\n",
        "        pos_enc = self.pos_encoder[:, :seq_len, :]\n",
        "        x = x + pos_enc\n",
        "        \n",
        "        # Transformer encoding\n",
        "        x = self.transformer(x)  # (batch_size, seq_length, d_model)\n",
        "        \n",
        "        # Pooling: mean and max\n",
        "        mean_pool = x.mean(dim=1)  # (batch_size, d_model)\n",
        "        max_pool = x.max(dim=1)[0]  # (batch_size, d_model)\n",
        "        pooled = torch.cat([mean_pool, max_pool], dim=-1)  # (batch_size, 2*d_model)\n",
        "        \n",
        "        # Project pooled representation\n",
        "        embedding = self.pool_proj(pooled)  # (batch_size, d_model)\n",
        "        embedding = self.layer_norm(embedding)\n",
        "        \n",
        "        return embedding\n",
        "\n",
        "# Test model\n",
        "test_model = SAINTTransformer(\n",
        "    input_dim=1,\n",
        "    d_model=EMBEDDING_DIM,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    dim_feedforward=512,\n",
        "    dropout=0.1,\n",
        "    seq_length=SEQ_LENGTH\n",
        ").to(device)\n",
        "\n",
        "test_input = torch.randn(4, SEQ_LENGTH).to(device)\n",
        "test_output = test_model(test_input)\n",
        "print(f\"âœ… SAINT Transformer model created\")\n",
        "print(f\"   Input shape: {test_input.shape}\")\n",
        "print(f\"   Output embedding shape: {test_output.shape}\")\n",
        "print(f\"   Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Generating triplets for contrastive learning...\n",
            "âœ… Generated 4213 triplets\n",
            "   Anchors shape: (4213, 30)\n",
            "   Positives shape: (4213, 30)\n",
            "   Negatives shape: (4213, 30)\n"
          ]
        }
      ],
      "source": [
        "def create_triplets(\n",
        "    sequences: np.ndarray,\n",
        "    targets: np.ndarray,\n",
        "    n_triplets: int = 10000,\n",
        "    margin: float = 0.1\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Create triplets for contrastive learning.\n",
        "    Anchor: random sequence\n",
        "    Positive: sequence with similar target (within margin)\n",
        "    Negative: sequence with different target (outside margin)\n",
        "    \n",
        "    Args:\n",
        "        sequences: (n_samples, seq_length)\n",
        "        targets: (n_samples,)\n",
        "        n_triplets: Number of triplets to generate\n",
        "        margin: Margin for similarity (positive within margin, negative outside)\n",
        "    \n",
        "    Returns:\n",
        "        anchors, positives, negatives: Each (n_triplets, seq_length)\n",
        "    \"\"\"\n",
        "    n_samples = len(sequences)\n",
        "    \n",
        "    # Normalize targets for similarity calculation\n",
        "    target_mean = targets.mean()\n",
        "    target_std = targets.std()\n",
        "    normalized_targets = (targets - target_mean) / (target_std + 1e-8)\n",
        "    \n",
        "    anchors = []\n",
        "    positives = []\n",
        "    negatives = []\n",
        "    \n",
        "    for _ in range(n_triplets):\n",
        "        # Random anchor\n",
        "        anchor_idx = np.random.randint(0, n_samples)\n",
        "        anchor = sequences[anchor_idx]\n",
        "        anchor_target_norm = normalized_targets[anchor_idx]\n",
        "        \n",
        "        # Find positive (similar target)\n",
        "        target_diff = np.abs(normalized_targets - anchor_target_norm)\n",
        "        positive_candidates = np.where(target_diff < margin)[0]\n",
        "        \n",
        "        if len(positive_candidates) > 1:\n",
        "            # Exclude anchor itself\n",
        "            positive_candidates = positive_candidates[positive_candidates != anchor_idx]\n",
        "        \n",
        "        if len(positive_candidates) > 0:\n",
        "            positive_idx = np.random.choice(positive_candidates)\n",
        "            positive = sequences[positive_idx]\n",
        "        else:\n",
        "            # If no positive found, use anchor (same sequence)\n",
        "            positive = anchor\n",
        "        \n",
        "        # Find negative (different target)\n",
        "        negative_candidates = np.where(target_diff > margin * 2)[0]\n",
        "        \n",
        "        if len(negative_candidates) > 0:\n",
        "            negative_idx = np.random.choice(negative_candidates)\n",
        "            negative = sequences[negative_idx]\n",
        "        else:\n",
        "            # If no negative found, use random different sequence\n",
        "            negative_idx = np.random.randint(0, n_samples)\n",
        "            while negative_idx == anchor_idx:\n",
        "                negative_idx = np.random.randint(0, n_samples)\n",
        "            negative = sequences[negative_idx]\n",
        "        \n",
        "        anchors.append(anchor)\n",
        "        positives.append(positive)\n",
        "        negatives.append(negative)\n",
        "    \n",
        "    return np.array(anchors), np.array(positives), np.array(negatives)\n",
        "\n",
        "# Create triplets\n",
        "print(\"ðŸ”„ Generating triplets for contrastive learning...\")\n",
        "triplet_anchors, triplet_positives, triplet_negatives = create_triplets(\n",
        "    sequences, targets, n_triplets=min(10000, len(sequences) // 2), margin=0.1\n",
        ")\n",
        "print(f\"âœ… Generated {len(triplet_anchors)} triplets\")\n",
        "print(f\"   Anchors shape: {triplet_anchors.shape}\")\n",
        "print(f\"   Positives shape: {triplet_positives.shape}\")\n",
        "print(f\"   Negatives shape: {triplet_negatives.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loss functions and datasets created\n"
          ]
        }
      ],
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"Triplet loss for contrastive learning.\"\"\"\n",
        "    \n",
        "    def __init__(self, margin: float = 1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    \n",
        "    def forward(self, anchor_emb, positive_emb, negative_emb):\n",
        "        \"\"\"\n",
        "        Compute triplet loss.\n",
        "        Loss = max(0, margin + d(anchor, positive) - d(anchor, negative))\n",
        "        \"\"\"\n",
        "        # Euclidean distance\n",
        "        pos_dist = torch.norm(anchor_emb - positive_emb, p=2, dim=1)\n",
        "        neg_dist = torch.norm(anchor_emb - negative_emb, p=2, dim=1)\n",
        "        \n",
        "        loss = torch.clamp(self.margin + pos_dist - neg_dist, min=0.0)\n",
        "        return loss.mean()\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    \"\"\"Dataset for sequences.\"\"\"\n",
        "    \n",
        "    def __init__(self, sequences: np.ndarray, targets: Optional[np.ndarray] = None):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        seq = torch.FloatTensor(self.sequences[idx])\n",
        "        if self.targets is not None:\n",
        "            target = torch.FloatTensor([self.targets[idx]])\n",
        "            return seq, target\n",
        "        return seq\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    \"\"\"Dataset for triplet contrastive learning.\"\"\"\n",
        "    \n",
        "    def __init__(self, anchors: np.ndarray, positives: np.ndarray, negatives: np.ndarray):\n",
        "        self.anchors = anchors\n",
        "        self.positives = positives\n",
        "        self.negatives = negatives\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.anchors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        anchor = torch.FloatTensor(self.anchors[idx])\n",
        "        positive = torch.FloatTensor(self.positives[idx])\n",
        "        negative = torch.FloatTensor(self.negatives[idx])\n",
        "        return anchor, positive, negative\n",
        "\n",
        "print(\"âœ… Loss functions and datasets created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train SAINT Transformer with Contrastive Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Data split:\n",
            "   Train: 6740 sequences\n",
            "   Test: 1686 sequences\n"
          ]
        }
      ],
      "source": [
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(sequences)), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_sequences = sequences[train_idx]\n",
        "train_targets = targets[train_idx]\n",
        "test_sequences = sequences[test_idx]\n",
        "test_targets = targets[test_idx]\n",
        "\n",
        "print(f\"âœ… Data split:\")\n",
        "print(f\"   Train: {len(train_sequences)} sequences\")\n",
        "print(f\"   Test: {len(test_sequences)} sequences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Training SAINT Transformer with contrastive learning...\n",
            "============================================================\n",
            "Epoch [5/30] - Loss: 0.9717\n",
            "Epoch [10/30] - Loss: 0.9427\n",
            "Epoch [15/30] - Loss: 0.9998\n",
            "Epoch [20/30] - Loss: 0.9987\n",
            "Epoch [25/30] - Loss: 1.0037\n",
            "Epoch [30/30] - Loss: 0.9968\n",
            "============================================================\n",
            "âœ… Training completed!\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ’¾ Model saved to saint_models/saint_transformer.pth\n"
          ]
        }
      ],
      "source": [
        "# Split data\n",
        "\n",
        "\n",
        "# Create triplets for training\n",
        "train_anchors, train_positives, train_negatives = create_triplets(\n",
        "    train_sequences, train_targets, n_triplets=min(5000, len(train_sequences) // 2), margin=0.1\n",
        ")\n",
        "\n",
        "# Create datasets and loaders\n",
        "triplet_dataset = TripletDataset(train_anchors, train_positives, train_negatives)\n",
        "triplet_loader = DataLoader(triplet_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "# Initialize model\n",
        "model = SAINTTransformer(\n",
        "    input_dim=1,\n",
        "    d_model=EMBEDDING_DIM,\n",
        "    nhead=8,\n",
        "    num_layers=4,\n",
        "    dim_feedforward=512,\n",
        "    dropout=0.1,\n",
        "    seq_length=SEQ_LENGTH\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "triplet_loss_fn = TripletLoss(margin=1.0)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Training\n",
        "num_epochs = 30\n",
        "train_losses = []\n",
        "\n",
        "print(\"ðŸš€ Training SAINT Transformer with contrastive learning...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    for anchor, positive, negative in triplet_loader:\n",
        "        anchor = anchor.to(device)\n",
        "        positive = positive.to(device)\n",
        "        negative = negative.to(device)\n",
        "        \n",
        "        # Get embeddings\n",
        "        anchor_emb = model(anchor)\n",
        "        positive_emb = model(positive)\n",
        "        negative_emb = model(negative)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = triplet_loss_fn(anchor_emb, positive_emb, negative_emb)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    epoch_loss /= len(triplet_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    scheduler.step(epoch_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… Training completed!\")\n",
        "\n",
        "# Plot training curve\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Triplet Loss')\n",
        "plt.title('SAINT Transformer Training Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(MODEL_DIR, 'saint_transformer.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'epoch': num_epochs,\n",
        "    'losses': train_losses,\n",
        "    'embedding_dim': EMBEDDING_DIM,\n",
        "    'seq_length': SEQ_LENGTH\n",
        "}, model_path)\n",
        "print(f\"ðŸ’¾ Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load SAINT Model (or Use Trained Model)\n",
        "\n",
        "Load a previously trained SAINT model or use the one just trained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ Loading saved SAINT model...\n",
            "ðŸ“‚ Loading SAINT model from saint_models/saint_transformer.pth...\n",
            "âœ… Model loaded successfully!\n",
            "   Embedding dimension: 128\n",
            "   Sequence length: 30\n",
            "   Trained for 30 epochs\n",
            "   Final training loss: 0.9968\n",
            "âœ… Model ready for embedding generation\n"
          ]
        }
      ],
      "source": [
        "def load_saint_model(\n",
        "    model_path: str,\n",
        "    embedding_dim: int = 128,\n",
        "    seq_length: int = 30,\n",
        "    device: torch.device = None\n",
        ") -> Tuple[nn.Module, Dict]:\n",
        "    \"\"\"\n",
        "    Load a saved SAINT transformer model.\n",
        "    \n",
        "    Args:\n",
        "        model_path: Path to saved model checkpoint (.pth file)\n",
        "        embedding_dim: Embedding dimension (must match saved model)\n",
        "        seq_length: Sequence length (must match saved model)\n",
        "        device: Device to load model on\n",
        "    \n",
        "    Returns:\n",
        "        model: Loaded SAINT transformer model\n",
        "        metadata: Dictionary with model metadata (epoch, losses, etc.)\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
        "    \n",
        "    print(f\"ðŸ“‚ Loading SAINT model from {model_path}...\")\n",
        "    \n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Extract metadata\n",
        "    metadata = {\n",
        "        'epoch': checkpoint.get('epoch', 'unknown'),\n",
        "        'losses': checkpoint.get('losses', []),\n",
        "        'embedding_dim': checkpoint.get('embedding_dim', embedding_dim),\n",
        "        'seq_length': checkpoint.get('seq_length', seq_length)\n",
        "    }\n",
        "    \n",
        "    # Use metadata from checkpoint if available\n",
        "    saved_embedding_dim = checkpoint.get('embedding_dim', embedding_dim)\n",
        "    saved_seq_length = checkpoint.get('seq_length', seq_length)\n",
        "    \n",
        "    if saved_embedding_dim != embedding_dim or saved_seq_length != seq_length:\n",
        "        print(f\"âš ï¸  Warning: Model config mismatch!\")\n",
        "        print(f\"   Saved: embedding_dim={saved_embedding_dim}, seq_length={saved_seq_length}\")\n",
        "        print(f\"   Requested: embedding_dim={embedding_dim}, seq_length={seq_length}\")\n",
        "        print(f\"   Using saved configuration...\")\n",
        "        embedding_dim = saved_embedding_dim\n",
        "        seq_length = saved_seq_length\n",
        "    \n",
        "    # Create model with correct architecture\n",
        "    model = SAINTTransformer(\n",
        "        input_dim=1,\n",
        "        d_model=embedding_dim,\n",
        "        nhead=8,\n",
        "        num_layers=4,\n",
        "        dim_feedforward=512,\n",
        "        dropout=0.1,\n",
        "        seq_length=seq_length\n",
        "    ).to(device)\n",
        "    \n",
        "    # Load state dict\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    \n",
        "    print(f\"âœ… Model loaded successfully!\")\n",
        "    print(f\"   Embedding dimension: {embedding_dim}\")\n",
        "    print(f\"   Sequence length: {seq_length}\")\n",
        "    print(f\"   Trained for {metadata['epoch']} epochs\")\n",
        "    if metadata['losses']:\n",
        "        final_loss = metadata['losses'][-1] if len(metadata['losses']) > 0 else 'unknown'\n",
        "        print(f\"   Final training loss: {final_loss:.4f}\")\n",
        "    \n",
        "    return model, metadata\n",
        "\n",
        "# Load model (use existing trained model or load from file)\n",
        "USE_SAVED_MODEL = True  # Set to True to load from file instead of using trained model\n",
        "SAVED_MODEL_PATH = os.path.join(MODEL_DIR, 'saint_transformer.pth')\n",
        "\n",
        "if USE_SAVED_MODEL and os.path.exists(SAVED_MODEL_PATH):\n",
        "    print(\"ðŸ“‚ Loading saved SAINT model...\")\n",
        "    model, model_metadata = load_saint_model(\n",
        "        SAVED_MODEL_PATH,\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        seq_length=SEQ_LENGTH,\n",
        "        device=device\n",
        "    )\n",
        "else:\n",
        "    print(\"âœ… Using model trained in previous cell\")\n",
        "    print(f\"   If you want to load a saved model, set USE_SAVED_MODEL = True\")\n",
        "\n",
        "print(\"âœ… Model ready for embedding generation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Embeddings for All Sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Generating embeddings for all sequences...\n",
            "âœ… Embeddings generated\n",
            "   Train embeddings shape: (6740, 128)\n",
            "   Test embeddings shape: (1686, 128)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def generate_embeddings(model: nn.Module, sequences: np.ndarray, batch_size: int = 64) -> np.ndarray:\n",
        "    \"\"\"Generate embeddings for sequences.\"\"\"\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    \n",
        "    dataset = SequenceDataset(sequences)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for seq in loader:\n",
        "            seq = seq.to(device)\n",
        "            emb = model(seq)\n",
        "            embeddings.append(emb.cpu().numpy())\n",
        "    \n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "print(\"ðŸ”„ Generating embeddings for all sequences...\")\n",
        "train_embeddings = generate_embeddings(model, train_sequences)\n",
        "test_embeddings = generate_embeddings(model, test_sequences)\n",
        "\n",
        "print(f\"âœ… Embeddings generated\")\n",
        "print(f\"   Train embeddings shape: {train_embeddings.shape}\")\n",
        "print(f\"   Test embeddings shape: {test_embeddings.shape}\")\n",
        "\n",
        "# Normalize embeddings\n",
        "#scaler_emb = RobustScaler()\n",
        "#train_embeddings_scaled = scaler_emb.fit_transform(train_embeddings)\n",
        "#test_embeddings_scaled = scaler_emb.transform(test_embeddings)\n",
        "\n",
        "#print(f\"âœ… Embeddings normalized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.397898  ,  0.9836996 ,  0.26774585,  0.7750549 , -1.0427008 ,\n",
              "        -1.5197794 ,  1.1700953 , -1.090172  ,  1.1549479 , -1.0115873 ,\n",
              "         0.19170561, -1.537496  ,  1.2620208 ,  1.4258355 ,  1.1259812 ,\n",
              "        -0.04365579, -0.52612525,  0.20863263, -2.0629413 ,  0.3007243 ,\n",
              "        -0.8357707 ,  0.8672385 ,  0.8415024 , -0.8743257 , -0.44643804,\n",
              "         0.9991053 ,  0.85994846,  0.5151596 ,  0.27635747,  0.89943546,\n",
              "        -0.19760697, -1.4107217 , -1.0876284 ,  1.0972923 , -0.39371356,\n",
              "        -0.93267894, -0.11407819,  0.05019319,  1.188981  ,  0.36422288,\n",
              "        -1.471313  ,  0.05734245,  0.54997945, -0.87672037,  1.831751  ,\n",
              "        -0.51988405,  0.07858109,  0.53403294, -2.0153687 , -0.45656174,\n",
              "         0.7098797 ,  0.36024442,  0.2770832 , -0.01594323, -0.30616444,\n",
              "        -1.59741   , -0.04890328,  0.50467503,  0.2864102 ,  1.0326341 ,\n",
              "         0.37261078, -0.34440392, -0.49209663,  0.9401851 , -1.5685843 ,\n",
              "         1.645008  , -1.2720462 ,  1.1400148 , -1.7496566 , -0.63453084,\n",
              "         0.4034287 ,  1.2562579 ,  0.73764217,  0.03089475,  0.8260354 ,\n",
              "        -1.3712533 , -1.7101027 , -0.5135181 ,  1.4683785 ,  0.21216105,\n",
              "         1.0542579 , -0.6204688 ,  0.47030544,  0.11651058, -1.2428831 ,\n",
              "        -1.5704323 , -1.7244772 ,  1.4308397 , -1.0847002 ,  1.1127855 ,\n",
              "        -1.1114527 ,  1.0421264 ,  0.735831  , -0.5571657 , -0.5946936 ,\n",
              "        -0.7155605 ,  0.36713985,  1.7297565 ,  0.7329569 ,  1.6281676 ,\n",
              "        -1.0601386 ,  0.59174263,  1.6541784 , -0.7056413 , -0.8445142 ,\n",
              "        -0.4274441 , -1.3010345 ,  0.8856574 ,  0.16656572, -0.82436943,\n",
              "        -0.23979169,  0.7944235 , -0.12536368, -1.4213688 ,  1.2530172 ,\n",
              "        -0.11625254,  0.7134527 , -0.5685391 , -0.46531102, -0.03908772,\n",
              "        -0.57502395,  0.5916291 ,  0.07323671,  0.698383  , -1.1734037 ,\n",
              "         1.3359281 , -0.80122817,  0.38957125]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_embeddings[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train H2O AutoML Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"25.0.1\" 2025-10-21; OpenJDK Runtime Environment Homebrew (build 25.0.1); OpenJDK 64-Bit Server VM Homebrew (build 25.0.1, mixed mode, sharing)\n",
            "  Starting server from /usr/local/Caskroom/miniconda/base/envs/aviator/lib/python3.12/site-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /var/folders/6c/ff6r44ps7yz46qjlbjy3q2d80000gn/T/tmpdav7wgwk\n",
            "  JVM stdout: /var/folders/6c/ff6r44ps7yz46qjlbjy3q2d80000gn/T/tmpdav7wgwk/h2o_traveller_started_from_python.out\n",
            "  JVM stderr: /var/folders/6c/ff6r44ps7yz46qjlbjy3q2d80000gn/T/tmpdav7wgwk/h2o_traveller_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-1.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-1 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-1 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-1 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-1 .h2o-table th,\n",
              "#h2o-table-1 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Asia/Kolkata</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.9</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>19 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_traveller_71hfe8</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>7.984 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>8</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>8</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.12.11 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ],
            "text/plain": [
              "--------------------------  --------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Asia/Kolkata\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.9\n",
              "H2O_cluster_version_age:    19 days\n",
              "H2O_cluster_name:           H2O_from_python_traveller_71hfe8\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    7.984 Gb\n",
              "H2O_cluster_total_cores:    8\n",
              "H2O_cluster_allowed_cores:  8\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.12.11 final\n",
              "--------------------------  --------------------------------"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        }
      ],
      "source": [
        "import h2o\n",
        "h2o.init(max_mem_size=\"8G\", nthreads=-1)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "X=np.concatenate([train_embeddings, test_embeddings], axis=0)\n",
        "y=np.concatenate([train_targets, test_targets], axis=0)\n",
        "\n",
        "feature_names = [f\"f_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df[\"target\"] = y\n",
        "\n",
        "hf = h2o.H2OFrame(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoML progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
              "=============\n",
              "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
              "Model Key: GLM_1_AutoML_1_20251214_01131\n",
              "</pre>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>GLM Model: summary</caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>family</th>\n",
              "<th>link</th>\n",
              "<th>regularization</th>\n",
              "<th>lambda_search</th>\n",
              "<th>number_of_predictors_total</th>\n",
              "<th>number_of_active_predictors</th>\n",
              "<th>number_of_iterations</th>\n",
              "<th>training_frame</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>gaussian</td>\n",
              "<td>identity</td>\n",
              "<td>Ridge ( lambda = 47.859 )</td>\n",
              "<td>nlambda = 30, lambda.max = 47.859, lambda.min = 47.859, lambda.1se = 47.859</td>\n",
              "<td>128</td>\n",
              "<td>128</td>\n",
              "<td>1</td>\n",
              "<td>AutoML_1_20251214_01131_training_Key_Frame__upload_b51921ec730d459de79be3609e94fdc.hex</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: glm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 13490.10077197039\n",
              "RMSE: 116.14689307928298\n",
              "MAE: 15.123743328649049\n",
              "RMSLE: 1.3924603087264045\n",
              "Mean Residual Deviance: 13490.10077197039\n",
              "R^2: 7.3901790164088155e-06\n",
              "Null degrees of freedom: 8425\n",
              "Residual degrees of freedom: 8297\n",
              "Null deviance: 113668429.13466145\n",
              "Residual deviance: 113667589.10462251\n",
              "AIC: 104300.78058056776</pre></div>\n",
              "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: glm\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 13493.560133526691\n",
              "RMSE: 116.16178430760561\n",
              "MAE: 15.122109108648385\n",
              "RMSLE: 1.3921488499337584\n",
              "Mean Residual Deviance: 13493.560133526691\n",
              "R^2: -0.00024904496921274166\n",
              "Null degrees of freedom: 8425\n",
              "Residual degrees of freedom: 8297\n",
              "Null deviance: 113679481.03315145\n",
              "Residual deviance: 113696737.68509589\n",
              "AIC: 104302.9410420956</pre></div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-3.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-3 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-3 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-3 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-3 .h2o-table th,\n",
              "#h2o-table-3 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Cross-Validation Metrics Summary: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>mean</th>\n",
              "<th>sd</th>\n",
              "<th>cv_1_valid</th>\n",
              "<th>cv_2_valid</th>\n",
              "<th>cv_3_valid</th>\n",
              "<th>cv_4_valid</th>\n",
              "<th>cv_5_valid</th></tr></thead>\n",
              "    <tbody><tr><td>aic</td>\n",
              "<td>20813.125</td>\n",
              "<td>1038.7305</td>\n",
              "<td>20499.893</td>\n",
              "<td>19730.844</td>\n",
              "<td>21986.22</td>\n",
              "<td>21831.393</td>\n",
              "<td>20017.275</td></tr>\n",
              "<tr><td>loglikelihood</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td></tr>\n",
              "<tr><td>mae</td>\n",
              "<td>15.122227</td>\n",
              "<td>1.5229641</td>\n",
              "<td>14.129768</td>\n",
              "<td>13.934664</td>\n",
              "<td>14.8771</td>\n",
              "<td>17.727934</td>\n",
              "<td>14.941668</td></tr>\n",
              "<tr><td>mean_residual_deviance</td>\n",
              "<td>13494.025</td>\n",
              "<td>8143.113</td>\n",
              "<td>9573.982</td>\n",
              "<td>6109.011</td>\n",
              "<td>23295.65</td>\n",
              "<td>21250.523</td>\n",
              "<td>7240.9585</td></tr>\n",
              "<tr><td>mse</td>\n",
              "<td>13494.025</td>\n",
              "<td>8143.113</td>\n",
              "<td>9573.982</td>\n",
              "<td>6109.011</td>\n",
              "<td>23295.65</td>\n",
              "<td>21250.523</td>\n",
              "<td>7240.9585</td></tr>\n",
              "<tr><td>null_deviance</td>\n",
              "<td>22735896.0000000</td>\n",
              "<td>13716207.0000000</td>\n",
              "<td>16140876.0000000</td>\n",
              "<td>10293110.0000000</td>\n",
              "<td>39249056.0000000</td>\n",
              "<td>35795440.0000000</td>\n",
              "<td>12201001.0000000</td></tr>\n",
              "<tr><td>r2</td>\n",
              "<td>-0.0003805</td>\n",
              "<td>0.0003963</td>\n",
              "<td>-0.0002039</td>\n",
              "<td>-0.0006417</td>\n",
              "<td>-0.0001101</td>\n",
              "<td>-0.0009416</td>\n",
              "<td>-0.0000053</td></tr>\n",
              "<tr><td>residual_deviance</td>\n",
              "<td>22739348.0000000</td>\n",
              "<td>13719993.0000000</td>\n",
              "<td>16141735.0000000</td>\n",
              "<td>10293684.0000000</td>\n",
              "<td>39253172.0000000</td>\n",
              "<td>35807132.0000000</td>\n",
              "<td>12201015.0000000</td></tr>\n",
              "<tr><td>rmse</td>\n",
              "<td>111.9010850</td>\n",
              "<td>34.859932</td>\n",
              "<td>97.84673</td>\n",
              "<td>78.160164</td>\n",
              "<td>152.62912</td>\n",
              "<td>145.77559</td>\n",
              "<td>85.09382</td></tr>\n",
              "<tr><td>rmsle</td>\n",
              "<td>1.3920708</td>\n",
              "<td>0.0164409</td>\n",
              "<td>1.3955752</td>\n",
              "<td>1.4089193</td>\n",
              "<td>1.3855766</td>\n",
              "<td>1.3671575</td>\n",
              "<td>1.4031254</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Scoring History: </caption>\n",
              "    <thead><tr><th></th>\n",
              "<th>timestamp</th>\n",
              "<th>duration</th>\n",
              "<th>iteration</th>\n",
              "<th>lambda</th>\n",
              "<th>predictors</th>\n",
              "<th>deviance_train</th>\n",
              "<th>deviance_xval</th>\n",
              "<th>deviance_se</th>\n",
              "<th>alpha</th>\n",
              "<th>iterations</th>\n",
              "<th>training_rmse</th>\n",
              "<th>training_deviance</th>\n",
              "<th>training_mae</th>\n",
              "<th>training_r2</th></tr></thead>\n",
              "    <tbody><tr><td></td>\n",
              "<td>2025-12-14 00:11:55</td>\n",
              "<td> 0.000 sec</td>\n",
              "<td>1</td>\n",
              "<td>.48E2</td>\n",
              "<td>129</td>\n",
              "<td>13490.1003098</td>\n",
              "<td>13494.0249030</td>\n",
              "<td>3641.7104464</td>\n",
              "<td>0.0</td>\n",
              "<td>None</td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td>\n",
              "<td></td></tr>\n",
              "<tr><td></td>\n",
              "<td>2025-12-14 00:11:55</td>\n",
              "<td> 0.012 sec</td>\n",
              "<td>2</td>\n",
              "<td>.3E2</td>\n",
              "<td>129</td>\n",
              "<td>13490.0909984</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>0.0</td>\n",
              "<td>2</td>\n",
              "<td>116.1468931</td>\n",
              "<td>13490.1007720</td>\n",
              "<td>15.1237433</td>\n",
              "<td>0.0000074</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "</div>\n",
              "<div style='margin: 1em 0 1em 0;'>\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption>Variable Importances: </caption>\n",
              "    <thead><tr><th>variable</th>\n",
              "<th>relative_importance</th>\n",
              "<th>scaled_importance</th>\n",
              "<th>percentage</th></tr></thead>\n",
              "    <tbody><tr><td>f_78</td>\n",
              "<td>0.0053954</td>\n",
              "<td>1.0</td>\n",
              "<td>0.0229018</td></tr>\n",
              "<tr><td>f_15</td>\n",
              "<td>0.0049144</td>\n",
              "<td>0.9108449</td>\n",
              "<td>0.0208600</td></tr>\n",
              "<tr><td>f_64</td>\n",
              "<td>0.0039658</td>\n",
              "<td>0.7350358</td>\n",
              "<td>0.0168336</td></tr>\n",
              "<tr><td>f_100</td>\n",
              "<td>0.0038783</td>\n",
              "<td>0.7188244</td>\n",
              "<td>0.0164623</td></tr>\n",
              "<tr><td>f_8</td>\n",
              "<td>0.0038556</td>\n",
              "<td>0.7146130</td>\n",
              "<td>0.0163659</td></tr>\n",
              "<tr><td>f_92</td>\n",
              "<td>0.0032535</td>\n",
              "<td>0.6030065</td>\n",
              "<td>0.0138099</td></tr>\n",
              "<tr><td>f_124</td>\n",
              "<td>0.0032522</td>\n",
              "<td>0.6027721</td>\n",
              "<td>0.0138045</td></tr>\n",
              "<tr><td>f_18</td>\n",
              "<td>0.0029106</td>\n",
              "<td>0.5394558</td>\n",
              "<td>0.0123545</td></tr>\n",
              "<tr><td>f_31</td>\n",
              "<td>0.0028820</td>\n",
              "<td>0.5341648</td>\n",
              "<td>0.0122333</td></tr>\n",
              "<tr><td>f_6</td>\n",
              "<td>0.0027110</td>\n",
              "<td>0.5024671</td>\n",
              "<td>0.0115074</td></tr>\n",
              "<tr><td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td>\n",
              "<td>---</td></tr>\n",
              "<tr><td>f_108</td>\n",
              "<td>0.0010655</td>\n",
              "<td>0.1974769</td>\n",
              "<td>0.0045226</td></tr>\n",
              "<tr><td>f_56</td>\n",
              "<td>0.0009976</td>\n",
              "<td>0.1848898</td>\n",
              "<td>0.0042343</td></tr>\n",
              "<tr><td>f_3</td>\n",
              "<td>0.0009217</td>\n",
              "<td>0.1708326</td>\n",
              "<td>0.0039124</td></tr>\n",
              "<tr><td>f_33</td>\n",
              "<td>0.0008512</td>\n",
              "<td>0.1577686</td>\n",
              "<td>0.0036132</td></tr>\n",
              "<tr><td>f_42</td>\n",
              "<td>0.0007926</td>\n",
              "<td>0.1469097</td>\n",
              "<td>0.0033645</td></tr>\n",
              "<tr><td>f_68</td>\n",
              "<td>0.0007313</td>\n",
              "<td>0.1355431</td>\n",
              "<td>0.0031042</td></tr>\n",
              "<tr><td>f_21</td>\n",
              "<td>0.0002194</td>\n",
              "<td>0.0406728</td>\n",
              "<td>0.0009315</td></tr>\n",
              "<tr><td>f_24</td>\n",
              "<td>0.0002165</td>\n",
              "<td>0.0401184</td>\n",
              "<td>0.0009188</td></tr>\n",
              "<tr><td>f_36</td>\n",
              "<td>0.0000238</td>\n",
              "<td>0.0044198</td>\n",
              "<td>0.0001012</td></tr>\n",
              "<tr><td>f_44</td>\n",
              "<td>0.0000196</td>\n",
              "<td>0.0036243</td>\n",
              "<td>0.0000830</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n",
              "<pre style='font-size: smaller; margin-bottom: 1em;'>[128 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
            ],
            "text/plain": [
              "Model Details\n",
              "=============\n",
              "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
              "Model Key: GLM_1_AutoML_1_20251214_01131\n",
              "\n",
              "\n",
              "GLM Model: summary\n",
              "    family    link      regularization             lambda_search                                                                number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
              "--  --------  --------  -------------------------  ---------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  --------------------------------------------------------------------------------------\n",
              "    gaussian  identity  Ridge ( lambda = 47.859 )  nlambda = 30, lambda.max = 47.859, lambda.min = 47.859, lambda.1se = 47.859  128                           128                            1                       AutoML_1_20251214_01131_training_Key_Frame__upload_b51921ec730d459de79be3609e94fdc.hex\n",
              "\n",
              "ModelMetricsRegressionGLM: glm\n",
              "** Reported on train data. **\n",
              "\n",
              "MSE: 13490.10077197039\n",
              "RMSE: 116.14689307928298\n",
              "MAE: 15.123743328649049\n",
              "RMSLE: 1.3924603087264045\n",
              "Mean Residual Deviance: 13490.10077197039\n",
              "R^2: 7.3901790164088155e-06\n",
              "Null degrees of freedom: 8425\n",
              "Residual degrees of freedom: 8297\n",
              "Null deviance: 113668429.13466145\n",
              "Residual deviance: 113667589.10462251\n",
              "AIC: 104300.78058056776\n",
              "\n",
              "ModelMetricsRegressionGLM: glm\n",
              "** Reported on cross-validation data. **\n",
              "\n",
              "MSE: 13493.560133526691\n",
              "RMSE: 116.16178430760561\n",
              "MAE: 15.122109108648385\n",
              "RMSLE: 1.3921488499337584\n",
              "Mean Residual Deviance: 13493.560133526691\n",
              "R^2: -0.00024904496921274166\n",
              "Null degrees of freedom: 8425\n",
              "Residual degrees of freedom: 8297\n",
              "Null deviance: 113679481.03315145\n",
              "Residual deviance: 113696737.68509589\n",
              "AIC: 104302.9410420956\n",
              "\n",
              "Cross-Validation Metrics Summary: \n",
              "                        mean          sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
              "----------------------  ------------  -----------  ------------  ------------  ------------  ------------  ------------\n",
              "aic                     20813.1       1038.73      20499.9       19730.8       21986.2       21831.4       20017.3\n",
              "loglikelihood           0             0            0             0             0             0             0\n",
              "mae                     15.1222       1.52296      14.1298       13.9347       14.8771       17.7279       14.9417\n",
              "mean_residual_deviance  13494         8143.11      9573.98       6109.01       23295.7       21250.5       7240.96\n",
              "mse                     13494         8143.11      9573.98       6109.01       23295.7       21250.5       7240.96\n",
              "null_deviance           2.27359e+07   1.37162e+07  1.61409e+07   1.02931e+07   3.92491e+07   3.57954e+07   1.2201e+07\n",
              "r2                      -0.000380497  0.000396287  -0.000203859  -0.000641739  -0.000110057  -0.000941559  -5.26978e-06\n",
              "residual_deviance       2.27393e+07   1.372e+07    1.61417e+07   1.02937e+07   3.92532e+07   3.58071e+07   1.2201e+07\n",
              "rmse                    111.901       34.8599      97.8467       78.1602       152.629       145.776       85.0938\n",
              "rmsle                   1.39207       0.0164409    1.39558       1.40892       1.38558       1.36716       1.40313\n",
              "\n",
              "Scoring History: \n",
              "    timestamp            duration    iteration    lambda    predictors    deviance_train    deviance_xval    deviance_se    alpha    iterations    training_rmse       training_deviance    training_mae        training_r2\n",
              "--  -------------------  ----------  -----------  --------  ------------  ----------------  ---------------  -------------  -------  ------------  ------------------  -------------------  ------------------  ----------------------\n",
              "    2025-12-14 00:11:55  0.000 sec   1            48        129           13490.1           13494            3641.71        0\n",
              "    2025-12-14 00:11:55  0.012 sec   2            30        129           13490.1           0                0              0        2             116.14689307928298  13490.10077197039    15.123743328649049  7.3901790164088155e-06\n",
              "\n",
              "Variable Importances: \n",
              "variable    relative_importance     scaled_importance     percentage\n",
              "----------  ----------------------  --------------------  ----------------------\n",
              "f_78        0.005395394284278154    1.0                   0.022901764124181188\n",
              "f_15        0.004914367105811834    0.9108448515304982    0.020859953943476305\n",
              "f_64        0.00396580807864666     0.7350358230913318    0.01683361704326105\n",
              "f_100       0.0038783408235758543   0.7188243563361254    0.01646234585552631\n",
              "f_8         0.003855618881061673    0.7146129972922847    0.016365898304062033\n",
              "f_92        0.0032534576021134853   0.6030064589707299    0.013809911688705396\n",
              "f_124       0.003252193098887801    0.6027720918125467    0.01380454426733023\n",
              "f_18        0.002910576993599534    0.539455847013957     0.012354490563724015\n",
              "f_31        0.002882029628381133    0.5341647850981326    0.012233315911761366\n",
              "f_6         0.002711008070036769    0.5024670908549684    0.011507382794924005\n",
              "---         ---                     ---                   ---\n",
              "f_108       0.0010654659708961844   0.1974769432515593    0.0045225703743115245\n",
              "f_56        0.000997553113847971    0.18488975249775147   0.004234301500681744\n",
              "f_3         0.0009217092301696539   0.17083259936265596   0.003912367895324292\n",
              "f_33        0.000851223710924387    0.15776858299398067   0.003613178873934449\n",
              "f_42        0.000792635721154511    0.14690969360000297   0.0033644911503829984\n",
              "f_68        0.0007313084206543863   0.13554309140767967   0.0031041759080810095\n",
              "f_21        0.000219445995753631    0.04067283764470802   0.0009314797340002201\n",
              "f_24        0.00021645436936523765  0.0401183598381257    0.0009187812140617785\n",
              "f_36        2.3846481781220064e-05  0.004419784824754558  0.00010122086953616435\n",
              "f_44        1.9554285245249048e-05  0.003624255098877394  8.300183540035104e-05\n",
              "[128 rows x 4 columns]\n",
              "\n",
              "\n",
              "[tips]\n",
              "Use `model.explain()` to inspect the model.\n",
              "--\n",
              "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from h2o.automl import H2OAutoML\n",
        "\n",
        "aml = H2OAutoML(\n",
        "    max_runtime_secs=600,   # 10 minutes\n",
        "    max_models=25,\n",
        "    seed=42,\n",
        "    sort_metric=\"RMSE\"\n",
        ")\n",
        "\n",
        "aml.train(\n",
        "    x=feature_names,\n",
        "    y=\"target\",\n",
        "    training_frame=hf\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_id                                                rmse      mse      mae      rmsle    mean_residual_deviance\n",
            "GLM_1_AutoML_1_20251214_01131                        116.162  13493.6  15.1221    1.39215                   13493.6\n",
            "DeepLearning_grid_1_AutoML_1_20251214_01131_model_1  116.194  13501    14.3435  nan                         13501\n",
            "DeepLearning_1_AutoML_1_20251214_01131               116.34   13534.9  13.2877  nan                         13534.9\n",
            "GBM_1_AutoML_1_20251214_01131                        116.467  13564.6  15.4667  nan                         13564.6\n",
            "XGBoost_grid_1_AutoML_1_20251214_01131_model_4       116.555  13585.1  14.7622  nan                         13585.1\n",
            "GBM_2_AutoML_1_20251214_01131                        117.74   13862.8  16.2772  nan                         13862.8\n",
            "GBM_grid_1_AutoML_1_20251214_01131_model_2           117.818  13881.1  17.4008  nan                         13881.1\n",
            "GBM_3_AutoML_1_20251214_01131                        118.202  13971.7  16.7513  nan                         13971.7\n",
            "GBM_4_AutoML_1_20251214_01131                        118.485  14038.7  17.1342  nan                         14038.7\n",
            "GBM_grid_1_AutoML_1_20251214_01131_model_4           118.592  14064.1  17.7221  nan                         14064.1\n",
            "[10 rows x 6 columns]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(aml.leaderboard.head())\n",
        "\n",
        "leader = aml.leader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 116.14689307928298\n",
            "MAE : 15.123743328649049\n",
            "R2  : 7.3901790164088155e-06\n"
          ]
        }
      ],
      "source": [
        "perf = leader.model_performance(hf)\n",
        "\n",
        "print(\"RMSE:\", perf.rmse())\n",
        "print(\"MAE :\", perf.mae())\n",
        "print(\"R2  :\", perf.r2())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Initializing H2O...\n",
            "H2O session _sid_9459 closed.\n",
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-6.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-6 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-6 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-6 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-6 .h2o-table th,\n",
              "#h2o-table-6 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>14 mins 11 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Asia/Kolkata</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.9</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>19 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_traveller_71hfe8</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>7.897 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>8</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>8</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.12.11 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ],
            "text/plain": [
              "--------------------------  --------------------------------\n",
              "H2O_cluster_uptime:         14 mins 11 secs\n",
              "H2O_cluster_timezone:       Asia/Kolkata\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.9\n",
              "H2O_cluster_version_age:    19 days\n",
              "H2O_cluster_name:           H2O_from_python_traveller_71hfe8\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    7.897 Gb\n",
              "H2O_cluster_total_cores:    8\n",
              "H2O_cluster_allowed_cores:  8\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.12.11 final\n",
              "--------------------------  --------------------------------"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Preparing data for H2O AutoML...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'train_embeddings_scaled' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Preparing data for H2O AutoML...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create DataFrames with embeddings and targets\u001b[39;00m\n\u001b[32m     14\u001b[39m train_df_h2o = pd.DataFrame(\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mtrain_embeddings_scaled\u001b[49m,\n\u001b[32m     16\u001b[39m     columns=[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33memb_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_embeddings_scaled.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m train_df_h2o[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m] = train_targets\n\u001b[32m     20\u001b[39m test_df_h2o = pd.DataFrame(\n\u001b[32m     21\u001b[39m     test_embeddings_scaled,\n\u001b[32m     22\u001b[39m     columns=[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33memb_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(test_embeddings_scaled.shape[\u001b[32m1\u001b[39m])]\n\u001b[32m     23\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'train_embeddings_scaled' is not defined"
          ]
        }
      ],
      "source": [
        "# Initialize H2O\n",
        "print(\"ðŸš€ Initializing H2O...\")\n",
        "try:\n",
        "    h2o.cluster().shutdown()\n",
        "except:\n",
        "    pass\n",
        "h2o.init(ip=\"localhost\", port=54321, nthreads=-1, max_mem_size=\"4G\")\n",
        "h2o.no_progress()  # Disable progress bars for cleaner output\n",
        "\n",
        "# Prepare data for H2O\n",
        "print(\"ðŸ“Š Preparing data for H2O AutoML...\")\n",
        "\n",
        "# Create DataFrames with embeddings and targets\n",
        "train_df_h2o = pd.DataFrame(\n",
        "    train_embeddings_scaled,\n",
        "    columns=[f'emb_{i}' for i in range(train_embeddings_scaled.shape[1])]\n",
        ")\n",
        "train_df_h2o['target'] = train_targets\n",
        "\n",
        "test_df_h2o = pd.DataFrame(\n",
        "    test_embeddings_scaled,\n",
        "    columns=[f'emb_{i}' for i in range(test_embeddings_scaled.shape[1])]\n",
        ")\n",
        "test_df_h2o['target'] = test_targets\n",
        "\n",
        "# Convert to H2O Frames\n",
        "train_h2o = h2o.H2OFrame(train_df_h2o)\n",
        "test_h2o = h2o.H2OFrame(test_df_h2o)\n",
        "\n",
        "# Set target column\n",
        "target = 'target'\n",
        "feature_cols = [f'emb_{i}' for i in range(train_embeddings_scaled.shape[1])]\n",
        "\n",
        "print(f\"âœ… Data prepared:\")\n",
        "print(f\"   Train samples: {train_h2o.nrows}\")\n",
        "print(f\"   Test samples: {test_h2o.nrows}\")\n",
        "print(f\"   Features: {len(feature_cols)}\")\n",
        "\n",
        "# Configure H2O AutoML\n",
        "print(\"\\\\nðŸš€ Training H2O AutoML model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "aml = H2OAutoML(\n",
        "    max_models=20,  # Maximum number of models\n",
        "    max_runtime_secs=600,  # Maximum runtime in seconds (10 minutes)\n",
        "    seed=42,\n",
        "    sort_metric=\"MAE\",  # Sort by Mean Absolute Error\n",
        "    stopping_metric=\"MAE\",\n",
        "    stopping_tolerance=0.001,\n",
        "    stopping_rounds=5,\n",
        "    balance_classes=False,\n",
        "    exclude_algos=[],  # Include all algorithms\n",
        "    verbosity=\"info\"\n",
        ")\n",
        "\n",
        "# Train AutoML\n",
        "aml.train(\n",
        "    x=feature_cols,\n",
        "    y=target,\n",
        "    training_frame=train_h2o,\n",
        "    validation_frame=test_h2o\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… H2O AutoML training completed!\")\n",
        "\n",
        "# Display leaderboard\n",
        "print(\"\\\\nðŸ“‹ Model Leaderboard:\")\n",
        "print(aml.leaderboard.as_data_frame().head(10))\n",
        "\n",
        "# Get best model\n",
        "best_model = aml.leader\n",
        "print(f\"\\\\nðŸ† Best Model: {best_model.model_id}\")\n",
        "print(f\"   Model Type: {type(best_model).__name__}\")\n",
        "\n",
        "# Save model\n",
        "h2o_model_path = os.path.join(MODEL_DIR, 'h2o_automl_model')\n",
        "model_path_best = h2o.save_model(model=best_model, path=h2o_model_path, force=True)\n",
        "print(f\"ðŸ’¾ H2O model saved to: {model_path_best}\")\n",
        "\n",
        "# Save AutoML object info\n",
        "h2o_info = {\n",
        "    'best_model_id': best_model.model_id,\n",
        "    'best_model_type': type(best_model).__name__,\n",
        "    'leaderboard': aml.leaderboard.as_data_frame().to_dict('records')[:5]  # Top 5 models\n",
        "}\n",
        "\n",
        "with open(os.path.join(MODEL_DIR, 'h2o_model_info.json'), 'w') as f:\n",
        "    json.dump(h2o_info, f, indent=2, default=str)\n",
        "print(f\"ðŸ’¾ Model info saved to: {os.path.join(MODEL_DIR, 'h2o_model_info.json')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluate H2O AutoML Performance Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Making predictions...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Making predictions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predictions on train set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_pred_h2o = \u001b[43mbest_model\u001b[49m.predict(train_h2o).as_data_frame()[\u001b[33m'\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      6\u001b[39m train_pred = np.maximum(\u001b[32m1.0\u001b[39m, train_pred_h2o)  \u001b[38;5;66;03m# Ensure >= 1.0\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Predictions on test set\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Make predictions using H2O best model\n",
        "print(\"ðŸ“Š Making predictions...\")\n",
        "\n",
        "# Predictions on train set\n",
        "train_pred_h2o = best_model.predict(train_h2o).as_data_frame()['predict'].values\n",
        "train_pred = np.maximum(1.0, train_pred_h2o)  # Ensure >= 1.0\n",
        "\n",
        "# Predictions on test set\n",
        "test_pred_h2o = best_model.predict(test_h2o).as_data_frame()['predict'].values\n",
        "test_pred = np.maximum(1.0, test_pred_h2o)  # Ensure >= 1.0\n",
        "\n",
        "print(\"âœ… Predictions completed\")\n",
        "\n",
        "# Calculate metrics\n",
        "train_mae = mean_absolute_error(train_targets, train_pred)\n",
        "train_rmse = np.sqrt(mean_squared_error(train_targets, train_pred))\n",
        "train_r2 = r2_score(train_targets, train_pred)\n",
        "train_mape = np.mean(np.abs((train_targets - train_pred) / train_targets)) * 100\n",
        "\n",
        "test_mae = mean_absolute_error(test_targets, test_pred)\n",
        "test_rmse = np.sqrt(mean_squared_error(test_targets, test_pred))\n",
        "test_r2 = r2_score(test_targets, test_pred)\n",
        "test_mape = np.mean(np.abs((test_targets - test_pred) / test_targets)) * 100\n",
        "\n",
        "# Asymmetric error analysis\n",
        "train_error = train_pred - train_targets\n",
        "test_error = test_pred - test_targets\n",
        "\n",
        "train_over_pred = np.mean(train_error[train_error > 0])  # Average over-prediction\n",
        "train_under_pred = np.mean(np.abs(train_error[train_error < 0]))  # Average under-prediction\n",
        "test_over_pred = np.mean(test_error[test_error > 0])\n",
        "test_under_pred = np.mean(np.abs(test_error[test_error < 0]))\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ“Š PERFORMANCE METRICS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nðŸ“ˆ TRAIN SET:\")\n",
        "print(f\"   MAE: {train_mae:.4f}\")\n",
        "print(f\"   RMSE: {train_rmse:.4f}\")\n",
        "print(f\"   RÂ²: {train_r2:.4f}\")\n",
        "print(f\"   MAPE: {train_mape:.2f}%\")\n",
        "print(f\"   Avg Over-prediction: {train_over_pred:.4f}\")\n",
        "print(f\"   Avg Under-prediction: {train_under_pred:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š TEST SET:\")\n",
        "print(f\"   MAE: {test_mae:.4f}\")\n",
        "print(f\"   RMSE: {test_rmse:.4f}\")\n",
        "print(f\"   RÂ²: {test_r2:.4f}\")\n",
        "print(f\"   MAPE: {test_mape:.2f}%\")\n",
        "print(f\"   Avg Over-prediction: {test_over_pred:.4f}\")\n",
        "print(f\"   Avg Under-prediction: {test_under_pred:.4f}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Scatter plots\n",
        "axes[0, 0].scatter(train_targets, train_pred, alpha=0.5, s=10)\n",
        "axes[0, 0].plot([train_targets.min(), train_targets.max()], \n",
        "                [train_targets.min(), train_targets.max()], 'r--', lw=2)\n",
        "axes[0, 0].set_xlabel('Actual')\n",
        "axes[0, 0].set_ylabel('Predicted')\n",
        "axes[0, 0].set_title(f'Train Set (RÂ² = {train_r2:.4f})')\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "axes[0, 1].scatter(test_targets, test_pred, alpha=0.5, s=10)\n",
        "axes[0, 1].plot([test_targets.min(), test_targets.max()], \n",
        "                [test_targets.min(), test_targets.max()], 'r--', lw=2)\n",
        "axes[0, 1].set_xlabel('Actual')\n",
        "axes[0, 1].set_ylabel('Predicted')\n",
        "axes[0, 1].set_title(f'Test Set (RÂ² = {test_r2:.4f})')\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Residual plots\n",
        "axes[1, 0].scatter(train_pred, train_error, alpha=0.5, s=10)\n",
        "axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1, 0].set_xlabel('Predicted')\n",
        "axes[1, 0].set_ylabel('Residuals')\n",
        "axes[1, 0].set_title('Train Residuals')\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "axes[1, 1].scatter(test_pred, test_error, alpha=0.5, s=10)\n",
        "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1, 1].set_xlabel('Predicted')\n",
        "axes[1, 1].set_ylabel('Residuals')\n",
        "axes[1, 1].set_title('Test Residuals')\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Error distribution\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(train_error, bins=50, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.xlabel('Error (Predicted - Actual)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Train Error Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(test_error, bins=50, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.xlabel('Error (Predicted - Actual)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Test Error Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Store error statistics for range prediction\n",
        "train_error_stats = {\n",
        "    'mean': np.mean(train_error),\n",
        "    'std': np.std(train_error),\n",
        "    'p5': np.percentile(train_error, 5),\n",
        "    'p95': np.percentile(train_error, 95),\n",
        "    'over_pred_mean': train_over_pred,\n",
        "    'under_pred_mean': train_under_pred\n",
        "}\n",
        "\n",
        "print(f\"\\nðŸ“Š Error Statistics (for range prediction):\")\n",
        "print(f\"   Mean: {train_error_stats['mean']:.4f}\")\n",
        "print(f\"   Std: {train_error_stats['std']:.4f}\")\n",
        "print(f\"   5th percentile: {train_error_stats['p5']:.4f}\")\n",
        "print(f\"   95th percentile: {train_error_stats['p95']:.4f}\")\n",
        "\n",
        "# Save error stats\n",
        "error_stats_path = os.path.join(MODEL_DIR, 'error_stats.json')\n",
        "with open(error_stats_path, 'w') as f:\n",
        "    json.dump({k: float(v) for k, v in train_error_stats.items()}, f, indent=2)\n",
        "print(f\"ðŸ’¾ Error statistics saved to {error_stats_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Prediction Pipeline with Range Estimation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Monitoring Pipeline for Live Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SAINTH2OPredictor:\n",
        "    \"\"\"Complete prediction pipeline: Sequence -> Embedding -> H2O AutoML -> Prediction + Range\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        h2o_model,\n",
        "        scaler_emb: RobustScaler,\n",
        "        error_stats: Dict,\n",
        "        seq_length: int = 30,\n",
        "        device: torch.device = None\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.h2o_model = h2o_model\n",
        "        self.scaler_emb = scaler_emb\n",
        "        self.error_stats = error_stats\n",
        "        self.seq_length = seq_length\n",
        "        self.device = device if device is not None else torch.device('cpu')\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Feature column names for H2O\n",
        "        self.feature_cols = [f'emb_{i}' for i in range(scaler_emb.n_features_in_)]\n",
        "    \n",
        "    def predict(\n",
        "        self,\n",
        "        sequence: np.ndarray,\n",
        "        confidence: float = 0.95\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Predict multiplier and range from sequence.\n",
        "        \n",
        "        Args:\n",
        "            sequence: (seq_length,) array of multipliers\n",
        "            confidence: Confidence level for range (default 0.95)\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with prediction, range_min, range_max, etc.\n",
        "        \"\"\"\n",
        "        # Ensure sequence is correct length\n",
        "        if len(sequence) != self.seq_length:\n",
        "            raise ValueError(f\"Sequence must be length {self.seq_length}, got {len(sequence)}\")\n",
        "        \n",
        "        # Generate embedding\n",
        "        seq_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            embedding = self.model(seq_tensor).cpu().numpy()\n",
        "        \n",
        "        # Scale embedding\n",
        "        embedding_scaled = self.scaler_emb.transform(embedding)\n",
        "        \n",
        "        # Convert to H2O Frame\n",
        "        pred_df = pd.DataFrame(\n",
        "            embedding_scaled,\n",
        "            columns=self.feature_cols\n",
        "        )\n",
        "        pred_h2o = h2o.H2OFrame(pred_df)\n",
        "        \n",
        "        # Predict multiplier\n",
        "        prediction_h2o = self.h2o_model.predict(pred_h2o).as_data_frame()['predict'].values[0]\n",
        "        prediction = max(1.0, float(prediction_h2o))  # Ensure >= 1.0\n",
        "        \n",
        "        # Calculate range based on error statistics\n",
        "        # Use asymmetric range: wider on positive side (over-prediction)\n",
        "        error_std = self.error_stats['std']\n",
        "        \n",
        "        # Lower bound: use lower percentile (more conservative)\n",
        "        lower_bound = prediction + self.error_stats['p5']\n",
        "        lower_bound = max(1.0, lower_bound)  # Ensure >= 1.0\n",
        "        \n",
        "        # Upper bound: use higher percentile with more penalty for over-prediction\n",
        "        # Since we penalize over-prediction more, make upper bound wider\n",
        "        upper_bound = prediction + self.error_stats['p95'] * 1.2  # 20% wider for safety\n",
        "        upper_bound = max(prediction, upper_bound)  # At least as high as prediction\n",
        "        \n",
        "        return {\n",
        "            'prediction': float(prediction),\n",
        "            'range_min': float(lower_bound),\n",
        "            'range_max': float(upper_bound),\n",
        "            'confidence': confidence\n",
        "        }\n",
        "    \n",
        "    def predict_batch(self, sequences: np.ndarray, confidence: float = 0.95) -> List[Dict]:\n",
        "        \"\"\"Predict for multiple sequences.\"\"\"\n",
        "        results = []\n",
        "        for seq in sequences:\n",
        "            results.append(self.predict(seq, confidence))\n",
        "        return results\n",
        "\n",
        "# Initialize predictor\n",
        "predictor = SAINTH2OPredictor(\n",
        "    model=model,\n",
        "    h2o_model=best_model,\n",
        "    scaler_emb=scaler_emb,\n",
        "    error_stats=train_error_stats,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"âœ… Prediction pipeline created\")\n",
        "\n",
        "# Test on a few sequences\n",
        "print(\"\\nðŸ§ª Testing prediction pipeline...\")\n",
        "test_seqs = test_sequences[:5]\n",
        "test_actuals = test_targets[:5]\n",
        "\n",
        "for i, (seq, actual) in enumerate(zip(test_seqs, test_actuals)):\n",
        "    result = predictor.predict(seq)\n",
        "    error = result['prediction'] - actual\n",
        "    in_range = (result['range_min'] <= actual <= result['range_max'])\n",
        "    \n",
        "    print(f\"\\nSequence {i+1}:\")\n",
        "    print(f\"  Actual: {actual:.4f}x\")\n",
        "    print(f\"  Predicted: {result['prediction']:.4f}x\")\n",
        "    print(f\"  Range: {result['range_min']:.4f}x - {result['range_max']:.4f}x\")\n",
        "    print(f\"  Error: {error:+.4f}\")\n",
        "    print(f\"  In Range: {'âœ…' if in_range else 'âŒ'}\")\n",
        "\n",
        "# Calculate range coverage on test set\n",
        "test_results = predictor.predict_batch(test_sequences[:100])  # Sample for speed\n",
        "test_range_coverage = sum(\n",
        "    1 for i, res in enumerate(test_results)\n",
        "    if res['range_min'] <= test_targets[i] <= res['range_max']\n",
        ") / len(test_results) * 100\n",
        "\n",
        "print(f\"\\nðŸ“Š Range Coverage (first 100 test samples): {test_range_coverage:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Complete Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize prediction log\n",
        "prediction_log = []\n",
        "pending_prediction_index = None\n",
        "pending_prediction_data = None\n",
        "\n",
        "def save_prediction_log():\n",
        "    \"\"\"Save prediction log to CSV.\"\"\"\n",
        "    if len(prediction_log) == 0:\n",
        "        return\n",
        "    log_df = pd.DataFrame(prediction_log)\n",
        "    log_df.to_csv(PREDICTION_LOG_FILE, index=False)\n",
        "    print(f\"ðŸ’¾ Prediction log saved to {PREDICTION_LOG_FILE}\")\n",
        "\n",
        "def get_sequence_for_prediction(df: pd.DataFrame, index: int, seq_length: int = 30) -> Optional[np.ndarray]:\n",
        "    \"\"\"Get sequence ending at index for prediction.\"\"\"\n",
        "    if index < seq_length:\n",
        "        return None\n",
        "    seq = df['multiplier'].iloc[index - seq_length:index].values\n",
        "    return seq\n",
        "\n",
        "def monitor_and_predict(check_interval: float = 2.0, max_iterations: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Monitor CSV for new data and make predictions using SAINT + H2O AutoML pipeline.\n",
        "    \n",
        "    Workflow:\n",
        "    1. Read CSV in loop\n",
        "    2. On new data:\n",
        "       - If no pending prediction -> predict for next index, store index\n",
        "       - If pending prediction -> check stored index, print actual, then predict next\n",
        "    \"\"\"\n",
        "    global df, prediction_log, pending_prediction_index, pending_prediction_data\n",
        "    \n",
        "    # Start from the last row we have data for\n",
        "    last_known_row = len(df) - 1\n",
        "    iteration = 0\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ðŸš€ Starting SAINT + H2O AutoML Prediction Agent\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ðŸ“ Monitoring: {CSV_FILE}\")\n",
        "    print(f\"â±ï¸  Check interval: {check_interval} seconds\")\n",
        "    print(f\"ðŸ”„ Starting from row {last_known_row} (last known index: {last_known_row})\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\\\nPress Ctrl+C to stop\\\\n\")\n",
        "    \n",
        "    try:\n",
        "        while True:\n",
        "            if max_iterations and iteration >= max_iterations:\n",
        "                break\n",
        "            \n",
        "            # Load current CSV\n",
        "            try:\n",
        "                current_df = load_csv_data(CSV_FILE)\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Error loading CSV: {e}\")\n",
        "                time.sleep(check_interval)\n",
        "                continue\n",
        "            \n",
        "            current_row_count = len(current_df)\n",
        "            \n",
        "            # Check if we have new data\n",
        "            if current_row_count > last_known_row + 1:\n",
        "                new_rows_count = current_row_count - (last_known_row + 1)\n",
        "                print(f\"\\\\nðŸ“ˆ New data detected: {new_rows_count} new row(s) (Total: {current_row_count}, Last known: {last_known_row})\")\n",
        "                \n",
        "                # Update df\n",
        "                df = current_df\n",
        "                \n",
        "                # Case 1: We have a pending prediction - check if actual is now available\n",
        "                if pending_prediction_index is not None:\n",
        "                    if pending_prediction_index < len(df):\n",
        "                        # Actual value is now available!\n",
        "                        actual_value = float(df['multiplier'].iloc[pending_prediction_index])\n",
        "                        actual_timestamp = df['timestamp'].iloc[pending_prediction_index]\n",
        "                        \n",
        "                        pred_value = pending_prediction_data['prediction']\n",
        "                        pred_min = pending_prediction_data['range_min']\n",
        "                        pred_max = pending_prediction_data['range_max']\n",
        "                        \n",
        "                        # Calculate errors\n",
        "                        error = actual_value - pred_value\n",
        "                        abs_error = abs(error)\n",
        "                        pct_error = abs(error / actual_value * 100) if actual_value > 0 else 0\n",
        "                        in_range = (pred_min <= actual_value <= pred_max)\n",
        "                        \n",
        "                        # Print actual value\n",
        "                        print(\"\\\\n\" + \"=\" * 80)\n",
        "                        print(\"âœ… ACTUAL MULTIPLIER\")\n",
        "                        print(\"=\" * 80)\n",
        "                        print(f\"ðŸ“Š Index: {pending_prediction_index}\")\n",
        "                        print(f\"ðŸ“Š Actual Multiplier: {actual_value:.4f}x\")\n",
        "                        print(f\"ðŸ”® Predicted: {pred_value:.4f}x\")\n",
        "                        print(f\"ðŸ“ Range: {pred_min:.4f}x - {pred_max:.4f}x\")\n",
        "                        print(f\"âŒ Error: {error:+.4f} ({pct_error:.2f}%)\")\n",
        "                        print(f\"{'âœ…' if in_range else 'âŒ'} In Range: {in_range}\")\n",
        "                        print(f\"â° Timestamp: {actual_timestamp}\")\n",
        "                        print(\"=\" * 80)\n",
        "                        \n",
        "                        # Update log entry\n",
        "                        if len(prediction_log) > 0:\n",
        "                            log_entry = prediction_log[-1]\n",
        "                            log_entry['actual_value'] = actual_value\n",
        "                            log_entry['actual_timestamp'] = actual_timestamp.isoformat() if hasattr(actual_timestamp, 'isoformat') else str(actual_timestamp)\n",
        "                            log_entry['error'] = error\n",
        "                            log_entry['abs_error'] = abs_error\n",
        "                            log_entry['pct_error'] = pct_error\n",
        "                            log_entry['in_range'] = in_range\n",
        "                            log_entry['status'] = 'completed'\n",
        "                        \n",
        "                        # Save log\n",
        "                        save_prediction_log()\n",
        "                        \n",
        "                        # Store index and clear pending\n",
        "                        processed_index = pending_prediction_index\n",
        "                        pending_prediction_index = None\n",
        "                        pending_prediction_data = None\n",
        "                        last_known_row = processed_index\n",
        "                \n",
        "                # Case 2: No pending prediction OR we just processed one -> make new prediction\n",
        "                if pending_prediction_index is None:\n",
        "                    next_prediction_index = last_known_row + 1\n",
        "                    \n",
        "                    # Check if we have enough data\n",
        "                    if len(df) < SEQ_LENGTH + 1:\n",
        "                        print(f\"âš ï¸  Insufficient data for prediction (need {SEQ_LENGTH + 1}, have {len(df)})\")\n",
        "                        last_known_row = current_row_count - 1\n",
        "                        time.sleep(check_interval)\n",
        "                        iteration += 1\n",
        "                        continue\n",
        "                    \n",
        "                    # Get sequence for prediction\n",
        "                    sequence = get_sequence_for_prediction(df, next_prediction_index, SEQ_LENGTH)\n",
        "                    \n",
        "                    if sequence is None:\n",
        "                        print(f\"âš ï¸  Could not get sequence for index {next_prediction_index}\")\n",
        "                        last_known_row = current_row_count - 1\n",
        "                        time.sleep(check_interval)\n",
        "                        iteration += 1\n",
        "                        continue\n",
        "                    \n",
        "                    # Make prediction\n",
        "                    print(f\"ðŸ”® Making prediction for index {next_prediction_index}...\")\n",
        "                    try:\n",
        "                        result = predictor.predict(sequence)\n",
        "                        \n",
        "                        pred_value = result['prediction']\n",
        "                        pred_min = result['range_min']\n",
        "                        pred_max = result['range_max']\n",
        "                        \n",
        "                        # Print prediction FIRST\n",
        "                        print(\"\\\\n\" + \"=\" * 80)\n",
        "                        print(\"ðŸ”® PREDICTION\")\n",
        "                        print(\"=\" * 80)\n",
        "                        print(f\"ðŸ“Š Predicting for index: {next_prediction_index}\")\n",
        "                        print(f\"ðŸ“Š Predicted Multiplier: {pred_value:.4f}x\")\n",
        "                        print(f\"ðŸ“ Range: {pred_min:.4f}x - {pred_max:.4f}x\")\n",
        "                        print(f\"â° Timestamp: {datetime.now().isoformat()}\")\n",
        "                        print(\"=\" * 80)\n",
        "                        print(f\"\\\\nâ³ Waiting for actual multiplier at index {next_prediction_index}...\")\n",
        "                        \n",
        "                        # Save prediction\n",
        "                        log_entry = {\n",
        "                            'prediction_index': next_prediction_index,\n",
        "                            'prediction_timestamp': datetime.now().isoformat(),\n",
        "                            'predicted_value': pred_value,\n",
        "                            'range_min': pred_min,\n",
        "                            'range_max': pred_max,\n",
        "                            'actual_value': None,\n",
        "                            'actual_timestamp': None,\n",
        "                            'error': None,\n",
        "                            'abs_error': None,\n",
        "                            'pct_error': None,\n",
        "                            'in_range': None,\n",
        "                            'status': 'pending'\n",
        "                        }\n",
        "                        \n",
        "                        prediction_log.append(log_entry)\n",
        "                        \n",
        "                        # Store pending prediction\n",
        "                        pending_prediction_index = next_prediction_index\n",
        "                        pending_prediction_data = result\n",
        "                        \n",
        "                    except Exception as e:\n",
        "                        print(f\"âš ï¸  Error making prediction: {e}\")\n",
        "                        last_known_row = current_row_count - 1\n",
        "            else:\n",
        "                # No new data\n",
        "                time.sleep(check_interval)\n",
        "            \n",
        "            iteration += 1\n",
        "            \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\\\n\\\\nâ¹ï¸  Monitoring stopped by user\")\n",
        "        print(\"\\\\nðŸ“Š Final Statistics:\")\n",
        "        if len(prediction_log) > 0:\n",
        "            completed = [p for p in prediction_log if p['status'] == 'completed']\n",
        "            if len(completed) > 0:\n",
        "                completed_df = pd.DataFrame(completed)\n",
        "                print(f\"   Total predictions: {len(prediction_log)}\")\n",
        "                print(f\"   Completed: {len(completed)}\")\n",
        "                print(f\"   Pending: {len(prediction_log) - len(completed)}\")\n",
        "                print(f\"   Average absolute error: {completed_df['abs_error'].mean():.4f}\")\n",
        "                print(f\"   Average percentage error: {completed_df['pct_error'].mean():.2f}%\")\n",
        "                print(f\"   Range coverage: {(completed_df['in_range'].sum() / len(completed) * 100):.1f}%\")\n",
        "        \n",
        "        save_prediction_log()\n",
        "        print(f\"\\\\nâœ… Prediction log saved to: {PREDICTION_LOG_FILE}\")\n",
        "\n",
        "print(\"âœ… Monitoring function ready\")\n",
        "print(\"\\\\nTo start monitoring, run:\")\n",
        "print(\"monitor_and_predict(check_interval=2.0)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save complete pipeline metadata\n",
        "pipeline_path = os.path.join(MODEL_DIR, 'complete_pipeline_metadata.json')\n",
        "pipeline_metadata = {\n",
        "    'saint_model_path': model_path,\n",
        "    'h2o_model_path': model_path_best,\n",
        "    'h2o_model_id': best_model.model_id,\n",
        "    'h2o_model_type': type(best_model).__name__,\n",
        "    'scaler_emb_path': os.path.join(MODEL_DIR, 'scaler_emb.pkl'),\n",
        "    'error_stats_path': error_stats_path,\n",
        "    'seq_length': SEQ_LENGTH,\n",
        "    'embedding_dim': EMBEDDING_DIM,\n",
        "    'test_metrics': {\n",
        "        'mae': float(test_mae),\n",
        "        'rmse': float(test_rmse),\n",
        "        'r2': float(test_r2),\n",
        "        'mape': float(test_mape)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save scaler\n",
        "import joblib\n",
        "joblib.dump(scaler_emb, pipeline_metadata['scaler_emb_path'])\n",
        "\n",
        "# Save metadata\n",
        "with open(pipeline_path, 'w') as f:\n",
        "    json.dump(pipeline_metadata, f, indent=2)\n",
        "print(f\"ðŸ’¾ Pipeline metadata saved to {pipeline_path}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 80)\n",
        "print(\"âœ… NOTEBOOK COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ðŸ“Š Model Performance:\")\n",
        "print(f\"   Test MAE: {test_mae:.4f}\")\n",
        "print(f\"   Test RMSE: {test_rmse:.4f}\")\n",
        "print(f\"   Test RÂ²: {test_r2:.4f}\")\n",
        "print(f\"   Test MAPE: {test_mape:.2f}%\")\n",
        "print(f\"\\\\nðŸ“ Models saved in: {MODEL_DIR}\")\n",
        "print(f\"ðŸ“ Prediction log: {PREDICTION_LOG_FILE}\")\n",
        "print(\"\\\\nðŸš€ Ready for monitoring!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Start Monitoring (Live Predictions)\n",
        "\n",
        "Run the cell below to start monitoring the CSV file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start monitoring\n",
        "# Uncomment to start:\n",
        "# monitor_and_predict(check_interval=2.0)\n",
        "\n",
        "# Or with limited iterations for testing:\n",
        "# monitor_and_predict(check_interval=2.0, max_iterations=10)\n",
        "\n",
        "print(\"Ready to start monitoring. Uncomment the monitor_and_predict() call above.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aviator",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
